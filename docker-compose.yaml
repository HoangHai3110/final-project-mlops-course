version: '3.8'

volumes:
  pgdata:
  minio-data:

services:
  postgres:
    image: postgres:15
    container_name: mlflow-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    command: -p ${POSTGRES_PORT}
    ports:
      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -p ${POSTGRES_PORT}"]
      interval: 5s
      timeout: 3s
      retries: 10

  minio:
    image: minio/minio:latest
    container_name: mlflow-minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # MinIO console
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 5s
      timeout: 3s
      retries: 20

  create-bucket:
    image: minio/mc:latest
    container_name: mlflow-create-bucket
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c '
        mc alias set myminio http://${MINIO_HOST}:${MINIO_PORT} ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD} &&
        mc mb --ignore-existing myminio/${MINIO_BUCKET:-mlflow}
      '
    restart: "no"

  mlflow:
    image: ghcr.io/mlflow/mlflow:${MLFLOW_VERSION}
    container_name: mlflow-server
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy
      create-bucket:
        condition: service_completed_successfully
    environment:
      # Backend store (Postgres)
      MLFLOW_BACKEND_STORE_URI: ${MLFLOW_BACKEND_STORE_URI}

      # Artifact store (MinIO/S3)
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      MLFLOW_S3_IGNORE_TLS: "true"

      # Server
      MLFLOW_HOST: ${MLFLOW_HOST}
      MLFLOW_PORT: ${MLFLOW_PORT}
      MLFLOW_SERVER_ALLOWED_HOSTS: ${MLFLOW_SERVER_ALLOWED_HOSTS}
    command: >
      /bin/bash -c "
        pip install --no-cache-dir psycopg2-binary boto3 &&
        mlflow server
          --backend-store-uri ${MLFLOW_BACKEND_STORE_URI}
          --artifacts-destination ${MLFLOW_DEFAULT_ARTIFACT_ROOT}
          --serve-artifacts
          --host ${MLFLOW_HOST}
          --allowed-hosts ${MLFLOW_SERVER_ALLOWED_HOSTS}
          --port ${MLFLOW_PORT}
      "
    ports:
      - "${MLFLOW_PORT}:${MLFLOW_PORT}"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:${MLFLOW_PORT}/health')"]
      interval: 10s
      timeout: 5s
      retries: 30

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: telco-api
    depends_on:
      mlflow:
        condition: service_healthy
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:${MLFLOW_PORT}
      - MODEL_URI=models:/telco-churn-model/Production
      - APP_BASE_URL=${APP_BASE_URL:-http://localhost:8000}
      - REPORTS_BASE_URL=${REPORTS_BASE_URL:-http://localhost:8081}
    ports:
      - "8000:8000"
    volumes:
    - ./reports:/app/reports
    - ./data:/app/data:ro
    networks:
      - default
    restart: unless-stopped

  airflow:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow
    depends_on:
      mlflow:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - PYTHONPATH=/opt/airflow/project
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./:/opt/airflow/project
    command: >
      bash -c "
        airflow db upgrade &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true &&
        airflow webserver --port 8080 &
        airflow scheduler
      "
    ports:
      - "8080:8080"
    networks:
      - default
    restart: unless-stopped

networks:
  default:
    name: mlflow-network
