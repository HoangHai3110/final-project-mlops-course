from typing import List, Optional
import os
import logging

import pandas as pd
import mlflow
import mlflow.sklearn
from fastapi import APIRouter, HTTPException

from scripts.service import monitoring
from scripts.service.schemas.request import TelcoFeatures, TelcoBatchRequest
from scripts.service.schemas.response import TelcoPrediction, TelcoBatchResponse

logger = logging.getLogger("telco-api")

router = APIRouter()

MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5050")
MODEL_URI = os.getenv("MODEL_URI", "models:/telco-churn-model/Production")

# cache model + l·ªói l·∫ßn load g·∫ßn nh·∫•t
_model = None
_model_error: Optional[str] = None


def get_model():
    """
    Lazy-load model t·ª´ MLflow.
    - L·∫ßn ƒë·∫ßu ti√™n g·ªçi s·∫Ω c·ªë g·∫Øng load model.
    - N·∫øu ƒë√£ load th√†nh c√¥ng th√¨ l·∫ßn sau d√πng l·∫°i _model.
    - N·∫øu t·ª´ng load l·ªói, l∆∞u l√Ω do v√†o _model_error v√† tr·∫£ HTTP 503.
    """
    global _model, _model_error

    if _model is not None:
        return _model

    if _model_error is not None:
        raise HTTPException(
            status_code=503,
            detail=f"Model not available (last error: {_model_error})",
        )

    try:
        if MLFLOW_TRACKING_URI:
            mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

        logger.info(f"Loading MLflow model from URI: {MODEL_URI}")
        _model = mlflow.sklearn.load_model(MODEL_URI)
        logger.info("‚úÖ Model loaded successfully")
        return _model

    except Exception as e:
        _model_error = repr(e)
        logger.error(f"‚ùå Failed to load model from MLflow: {_model_error}")
        raise HTTPException(
            status_code=503,
            detail="Model could not be loaded from MLflow; please try again later.",
        )


# ‚ùå KH√îNG c·∫ßn /health ·ªü ƒë√¢y n·ªØa v√¨ b·∫°n ƒë√£ c√≥ /health trong app ch√≠nh
# N·∫øu v·∫´n mu·ªën gi·ªØ health ri√™ng cho model, c√≥ th·ªÉ ƒë·ªïi path th√†nh "/health/model"
# ho·∫∑c xo√° lu√¥n block d∆∞·ªõi:

# @router.get("/health")
# def health_check():
#     """
#     Endpoint health ƒë∆°n gi·∫£n cho Prometheus / browser.
#     KH√îNG ph·ª• thu·ªôc v√†o model, lu√¥n tr·∫£ 200 n·∫øu API s·ªëng.
#     """
#     return {"status": "ok"}


@router.get("/model_info")
def model_info():
    """
    Tr·∫£ v·ªÅ th√¥ng tin c∆° b·∫£n v·ªÅ MLflow & tr·∫°ng th√°i model (debug).
    """
    return {
        "tracking_uri": MLFLOW_TRACKING_URI,
        "model_uri": MODEL_URI,
        "model_loaded": _model is not None,
        "last_error": _model_error,
    }


@router.post("/predict", response_model=TelcoPrediction)
def predict(features: TelcoFeatures):
    """
    Nh·∫≠n th√¥ng tin 1 kh√°ch h√†ng, tr·∫£ v·ªÅ x√°c su·∫•t & label churn.
    N·∫øu model ch∆∞a load ƒë∆∞·ª£c ‚Üí HTTP 503 (nh∆∞ng app kh√¥ng crash).
    """
    model = get_model()  # c√≥ th·ªÉ raise HTTPException 503

    df = pd.DataFrame([features.dict()])
    proba = model.predict_proba(df)[:, 1]
    pred = (proba >= 0.5).astype(int)

    # üîÅ Log v√†o h·ªá th·ªëng monitoring ƒë·ªÉ d√πng drift detection
    monitoring.log_prediction_for_monitoring(
        features.dict(),
        int(pred[0]),  # ho·∫∑c d√πng label kh√°c n·∫øu b·∫°n mu·ªën
    )

    return TelcoPrediction(
        churn_probability=float(proba[0]),
        churn_predicted=int(pred[0]),
    )


@router.post("/predict_batch", response_model=TelcoBatchResponse)
def predict_batch(request: TelcoBatchRequest):
    """
    Nh·∫≠n nhi·ªÅu kh√°ch h√†ng c√πng l√∫c (records), tr·∫£ list prediction t∆∞∆°ng ·ª©ng.
    """
    model = get_model()  # c√≥ th·ªÉ raise HTTPException 503

    if not request.records:
        return TelcoBatchResponse(predictions=[])

    df = pd.DataFrame([r.dict() for r in request.records])
    proba = model.predict_proba(df)[:, 1]
    pred = (proba >= 0.5).astype(int)

    preds: List[TelcoPrediction] = []
    for record, p, y in zip(request.records, proba, pred):
        # üîÅ Log t·ª´ng record cho monitoring
        monitoring.log_prediction_for_monitoring(
            record.dict(),
            int(y),
        )

        preds.append(
            TelcoPrediction(
                churn_probability=float(p),
                churn_predicted=int(y),
            )
        )

    return TelcoBatchResponse(predictions=preds)
